# PyTorch 深度学习:60分钟快速入门 （官方）

本章为官方网站的 [Deep Learning with PyTorch: A 60 Minute Blitz] (https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) 的中文翻译

## **PyTorch 是什么**

Pytorch 是一个基于 Python 的科学计算库，它面向以下两种人群：

- 希望将其代替 Numpy 来利用 GPUs 的威力；
- 一个可以提供更加灵活和快速的深度学习研究平台。

## 对比 PyTorch 和 TensorFlow

PyTorch 和 TensorFlow 是两个非常受欢迎的深度学习框架，它们都具有各自的优点和适用场景。

以下是 PyTorch 和 TensorFlow 的一些主要差异：

1. 编程风格：PyTorch 倾向于使用动态图（eager execution），即按照代码的执行顺序来定义和计算计算图，这使得编写和调试代码更加直观和易于理解。而 TensorFlow 则使用静态图（static graph），即首先定义计算图，然后再执行计算，这使得可以更好地进行计算图优化和加速。
2. 灵活性：由于 PyTorch 的动态图特性，它更加灵活，可以更轻松地进行调试和实验，而 TensorFlow 更加适用于部署和生产环境，具有更好的计算性能和模型优化。
3. 代码复杂度：相比 TensorFlow，PyTorch 的代码通常更短、更易于理解和调试。这使得 PyTorch 更适合于初学者或快速原型开发。
4. 社区支持：由于 TensorFlow 发布的时间更早，它有一个更大的社区，有更多的教程、示例和第三方库。而 PyTorch 社区正在迅速增长，也有大量的教程和示例可供学习和参考。
5. 计算速度：TensorFlow 在大规模分布式环境中具有更好的计算性能和扩展性，适用于处理大型数据集和复杂的模型。而 PyTorch 在小型和中等规模的数据集上运行速度更快，并且更适合于探索性数据分析、原型设计和小规模的训练任务。

总之，选择 PyTorch 还是 TensorFlow 取决于具体的需求和使用场景。如果你是初学者或想快速原型开发，那么 PyTorch 可能更适合你。如果你需要处理大型数据集或复杂的模型，那么 TensorFlow 可能更适合你。

## 张量(Tensors)

张量与NumPy的ndarrays类似，此外，
张量也可以在GPU上使用以加速计算。

```python
from __future__ import print_function
import torch
```

创建一个未初始化的5x3矩阵：

```python
x = torch.empty(5, 3)
print(x)
```

```
tensor([[-1.8736e-02,  5.3810e-43, -1.8736e-02],
        [ 5.3810e-43, -1.8736e-02,  5.3810e-43],
        [-1.8736e-02,  5.3810e-43, -1.8736e-02],
        [ 5.3810e-43, -1.8736e-02,  5.3810e-43],
        [-1.8736e-02,  5.3810e-43, -1.8736e-02]])
```

创建一个随机初始化的矩阵：

```python
x = torch.rand(5, 3)
print(x)
tensor([[0.1884, 0.9676, 0.0932],
        [0.0237, 0.8706, 0.1165],
        [0.8923, 0.6846, 0.2428],
        [0.1050, 0.1057, 0.4467],
        [0.2271, 0.8529, 0.5744]])
```

构造一个填充零且dtype long的矩阵：

```python
x = torch.zeros(5, 3, dtype=torch.long)
print(x)
tensor([[0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, 0]])
```

直接从数据创建张量：

```python
x = torch.tensor([5.5, 3])
print(x)
tensor([5.5000, 3.0000])
```

或基于现有张量创建张量。 这些方法将重复使用输入张量的属性，例如dtype，除非用户提供新值

```python
x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes
print(x)

x = torch.randn_like(x, dtype=torch.float)    # override dtype!
print(x)                                      # result has the same size
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
tensor([[-0.6246, -0.3308,  1.0961],
        [-0.2643, -1.9371, -0.7324],
        [-1.0433,  1.8659, -0.2630],
        [-0.5869, -0.8914,  1.2099],
        [-0.7889,  0.0762,  0.3997]])
```

打印它的大小：

```python
print(x.size())
torch.Size([5, 3])
```

## 运算(Operations)

运算有多种语法实现。在下面的示例中，我们将看一下加法运算。

加法：语法1

```python
y = torch.rand(5, 3)
print(x + y)
tensor([[-0.5411, -0.2331,  1.4236],
        [ 0.4124, -1.0028, -0.6942],
        [-0.5186,  2.3691,  0.6042],
        [-0.3107, -0.7324,  1.7120],
        [-0.5278,  0.2224,  1.1851]])
```

加法：语法2

```python
print(torch.add(x, y))
tensor([[-0.5411, -0.2331,  1.4236],
        [ 0.4124, -1.0028, -0.6942],
        [-0.5186,  2.3691,  0.6042],
        [-0.3107, -0.7324,  1.7120],
        [-0.5278,  0.2224,  1.1851]])
```

加法：提供输出张量作为参数(argument)

```python
result = torch.empty(5, 3)
torch.add(x, y, out=result)
print(result)
tensor([[-0.5411, -0.2331,  1.4236],
        [ 0.4124, -1.0028, -0.6942],
        [-0.5186,  2.3691,  0.6042],
        [-0.3107, -0.7324,  1.7120],
        [-0.5278,  0.2224,  1.1851]])
```

加法：直接修改 tensor 变量(in-place)

```python
# adds x to y
y.add_(x)
print(y)
tensor([[-0.5411, -0.2331,  1.4236],
        [ 0.4124, -1.0028, -0.6942],
        [-0.5186,  2.3691,  0.6042],
        [-0.3107, -0.7324,  1.7120],
        [-0.5278,  0.2224,  1.1851]])
```

#### 注

任何使张量就地发生变化的操作都将使用 ``_``. 如: ``x.copy_(y)``, ``x.t_()``, 会改变 ``x``.